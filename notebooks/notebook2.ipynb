{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import email\n",
    "import re\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/extracted_emails\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_email_text(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"latin-1\") as f:\n",
    "        msg = email.message_from_file(f)\n",
    "        subject = msg[\"Subject\"] if msg[\"Subject\"] else \"\"\n",
    "        content = \"\"\n",
    "        if msg.is_multipart():\n",
    "            for part in msg.walk():\n",
    "                if part.get_content_type() == \"text/plain\":\n",
    "                    content += part.get_payload(decode=True).decode(\"latin-1\", errors=\"ignore\")\n",
    "        else:\n",
    "            content = msg.get_payload(decode=True).decode(\"latin-1\", errors=\"ignore\")\n",
    "        return subject + \" \" + content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_emails(folder, label):\n",
    "    emails = []\n",
    "    for root, _, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            text = extract_email_text(file_path)\n",
    "            emails.append((text, label))\n",
    "    return emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_emails = load_emails(os.path.join(data_dir, \"spam\"), \"spam\")\n",
    "not_spam_emails = load_emails(os.path.join(data_dir, \"easy_ham\"), \"not_spam\") + \\\n",
    "                   load_emails(os.path.join(data_dir, \"hard_ham\"), \"not_spam\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(spam_emails + not_spam_emails, columns=[\"text\", \"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Data Sample:\n",
      "                                                text label\n",
      "0   mv 1 00001bfc8d64d12b325ff385cca8d07b84288\\nm...  spam\n",
      "1  life insurance  why pay more doctype html publ...  spam\n",
      "2  ilug guaranteed to lose 1012 lbs in 30 days 10...  spam\n",
      "3  guaranteed to lose 1012 lbs in 30 days        ...  spam\n",
      "4  re fw user name  password to membership to 5 s...  spam\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaned Data Sample:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[\"text\"], df[\"label\"], test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9658\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam       0.97      0.99      0.98       547\n",
      "        spam       0.97      0.91      0.94       214\n",
      "\n",
      "    accuracy                           0.97       761\n",
      "   macro avg       0.97      0.95      0.96       761\n",
      "weighted avg       0.97      0.97      0.97       761\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Spam\n"
     ]
    }
   ],
   "source": [
    "def predict_email(text):\n",
    "    cleaned_text = preprocess_text(text)\n",
    "    text_tfidf = vectorizer.transform([cleaned_text])\n",
    "    prediction = model.predict(text_tfidf)[0]\n",
    "    return \"Spam\" if prediction == \"spam\" else \"Not-Spam\"\n",
    "\n",
    "email_text = \"\"\" \n",
    "Subject: ðŸŽ‰ YOU JUST WON $5,000,000! CLAIM NOW ðŸŽ‰  \n",
    "\n",
    "From: lottery@mega-winner.com  \n",
    "To: user@example.com  \n",
    "\n",
    "Dear Winner,  \n",
    "\n",
    "Congratulations! You have been randomly selected as the **GRAND PRIZE WINNER** of our **$5,000,000 Mega Jackpot**.  \n",
    "\n",
    "To claim your prize:  \n",
    "âœ… Reply with your **full name, address, and phone number**  \n",
    "âœ… Pay a **small processing fee of $99**  \n",
    "âœ… Receive your winnings within 24 hours!  \n",
    "\n",
    "Hurry! Your prize will be forfeited if unclaimed.  \n",
    "\n",
    "Best regards,  \n",
    "Jack Thompson  \n",
    "Mega Lottery Promotions  \n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(\"Prediction:\", predict_email(email_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"../models\", \"spam_classifier_LogisticRegressi.pkl\"), \"wb\") as model_file:\n",
    "    pickle.dump((vectorizer, model), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
